{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlagiarismDetectionNLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKgCZCVnTvxm",
        "colab_type": "text"
      },
      "source": [
        "# Detección de plagio utilizando bigramas y sentence embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agthj3GCUB09",
        "colab_type": "text"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En el trabajo \"An Improved SRL based Plagiarism Detection Technique using Sentence Ranking\" por Merin Paul y Sangeetha Jamal (1) se presenta un método de detección de plagio usando técnicas de Natural Language Processing (NLP) que consiste en:\n",
        "\n",
        "1. Preprocesamiento\n",
        "  * Segmentación del texto de entrada\n",
        "  * Extracción de stopwords\n",
        "\n",
        "2. Obtención de candidatos\n",
        "  \n",
        "  Obtención de los textos pertenecientes a un corpus que podrían haber sufrido plagio por parte del documento sospechoso. La misma se realiza utilizando el coeficiente de similitud de Jaccard.\n",
        "\n",
        "3. Ranking de oraciones\n",
        "\n",
        "  Selección de las oraciones con mayor posibilidad de contener plagio de un documento original. Dicha selección se obtiene realizando una vectorización sencilla de las oraciones y aplicando el método de similaridad coseno.\n",
        "  \n",
        "  La vectorización realizada consiste en tomar el conjunto S de términos pertenecientes al documento original de cardinalidad N y vectorizar cada oración como un vector (t1, t2, ..., tN); donde ti es igual a 1 si el término i está presente en la oración, 0 en otro caso.\n",
        "\n",
        "  Luego, siendo A y B los vectores asociados a dos oraciones, la similaridad coseno se calcula de la siguiente forma:\n",
        "\n",
        "  ![Similaridad Coseno](https://i.stack.imgur.com/Qmq2w.png)\n",
        "\n",
        "  Cuanto mayor resulta el valor de la similaridad coseno, más similares son las oraciones y mayor posibilidad existe de que la oración B sea plagio de la oración A.\n",
        "\n",
        "4. Semantic Role Labeling\n",
        "\n",
        "  En NLP, realizar Semantic Role Labeling implica asignar a cada parte de una oración un propósito. El objetivo de la técnica es, a partir de una oración; determinar los fragmentos de la misma que responden a \"qué\", \"quién\", \"donde\", \"cómo\", \"cuando\", etc.\n",
        "  El siguiente paso es, para los pares de oraciones que obtuvieron valores altos en la etapa anterior; aplicar Semantic Role Labeling, información que se utilizará en la etapa siguiente.\n",
        "\n",
        "5. Detección de similaridad\n",
        "\n",
        "  En esta última etapa se evalúa la similaridad de los pares de oraciónes obtenidos comparando los roles semánticos detectados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Okv1HtZyO1",
        "colab_type": "text"
      },
      "source": [
        "En este trabajo, dadas las problematicas que implica aplicar Semantic Role Labeling (especialmente en el idioma español), implementaremos una simplificación de este método de detección de plagio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIeUsYzCaRVM",
        "colab_type": "text"
      },
      "source": [
        "## Método propuesto\n",
        "\n",
        "A continuación, presentamos el método propuesto.\n",
        "\n",
        "Las primeras dos etapas se mantienen iguales al método presentado por Paul y Jamal, siendo estas el preprocesamiento y la obtención de candidatos.\n",
        "\n",
        "Una vez realizadas dichas etapas, se realiza el siguiente procedimiento.\n",
        "\n",
        "1. Por cada oración perteneciente al documento sospechoso, se computa su sentence embedding.\n",
        "2. Cada una de dichas oraciones se compara con las oraciones del documento original, computando el sentence embedding de la oración original y aplicando similaridad coseno entre los dos resultados.\n",
        "3. Una oración se considera plagio cuando al menos una similaridad coseno con las oraciones de los documentos originales resultó alta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63JRnUeqcEQJ",
        "colab_type": "text"
      },
      "source": [
        "### Cálculo de los sentence embeddings\n",
        "\n",
        "Para el cómputo de los embeddings, se utiliza el modelo preentrenado [Google Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/3) en su versión multilenguaje V2. El mismo se encuentra entrenado con datos provenientes de 16 idiomas distíntos, incluido el español, y a probado tener buenos resultados en benchmarks de Semantic Similarity Retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI1R2RyodEMf",
        "colab_type": "text"
      },
      "source": [
        "## Implementación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSwhTjbdW5Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instalación de dependencias\n",
        "\n",
        "!pip3 install tensorflow_text>=2.0.0rc0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc1NQK_3XTIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import bigrams, word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBgDrNc_diRb",
        "colab_type": "code",
        "outputId": "08128d3e-47a0-4e67-90bc-c5c2c6e25037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Descarga de datos necesarios de nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXST3_kxXetK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtención del modelo de vectorización de oraciones entrenado\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EELktLrcgpr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocesamiento\n",
        "\n",
        "spanish_stopwords = stopwords.words('spanish')\n",
        "\n",
        "def preprocess_document(text):\n",
        "    return ' '.join([word.lower() for word in word_tokenize(text) if word.lower() not in spanish_stopwords])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tA6AcTLeqyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtención de candidatos\n",
        "\n",
        "def jaccard_similarity_coefficient(suspect_n_grams, original_n_grams):\n",
        "    return len(suspect_n_grams.intersection(original_n_grams)) / len(suspect_n_grams.union(original_n_grams))\n",
        "\n",
        "def get_text_bygrams(text):\n",
        "    return set(bigrams(word_tokenize(text)))\n",
        "\n",
        "def may_be_plagiarism_of(suspect, original, threshold=0.2):\n",
        "    preprocessed_original = preprocess_document(original)\n",
        "    preprocessed_suspect = preprocess_document(suspect)    \n",
        "    bigrams_original = get_text_bygrams(preprocessed_original)\n",
        "    bigrams_suspect = get_text_bygrams(preprocessed_suspect)\n",
        "    coefficient = jaccard_similarity_coefficient(\n",
        "        bigrams_suspect, bigrams_original)\n",
        "    return coefficient > threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lodzqU93hjgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detección de oraciones que incurrieron en plagio\n",
        "\n",
        "def sentence_is_semantically_similar(suspect_sentence, original_sentence, threshold=0.7):\n",
        "    suspect_embedding = embed(suspect_sentence)[\"outputs\"].numpy().reshape(1, 512)\n",
        "    original_embedding = embed(original_sentence)[\"outputs\"].numpy().reshape(1, 512)\n",
        "    return cosine_similarity(suspect_embedding, original_embedding) >= threshold\n",
        "\n",
        "def any_match(collection, function):\n",
        "    for element in collection:\n",
        "        if function(element):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def sentence_is_plagiarism(suspect_sentence, original_document, cosine_similarity_threshold=0.7):\n",
        "    return any_match(\n",
        "        sent_tokenize(original_document),\n",
        "        lambda original_sentence: sentence_is_semantically_similar(suspect_sentence, original_sentence, cosine_similarity_threshold)\n",
        "    )\n",
        "\n",
        "def plagiarised_sentences(suspect_document, original_document, cosine_similarity_threshold=0.7):\n",
        "    suspect_sentences = sent_tokenize(suspect_document)\n",
        "    return list(\n",
        "        filter(\n",
        "            lambda suspect_sentence: sentence_is_plagiarism(suspect_sentence, original_document, cosine_similarity_threshold),\n",
        "            suspect_sentences\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phafEcEXj2VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Porcentaje de plagio en un documento\n",
        "\n",
        "def plagiarism_percentage(suspect_document, original_document, cosine_similarity_threshold=0.7):\n",
        "    n_plagiarised = len(plagiarised_sentences(suspect_document, original_document))\n",
        "    n_total = len(sent_tokenize(suspect_document))\n",
        "    return n_plagiarised / n_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhE80Mlmuk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "49d1a49f-5c20-4500-dcf6-f1d708d54616"
      },
      "source": [
        "orig = \"Hola soy Pablo. Me gusta la naranja.\"\n",
        "plag = \"Me gusta la naranja. Él se llama Pablo.\"\n",
        "puede_ser_plagio = may_be_plagiarism_of(plag, orig)\n",
        "porcentaje_de_plagio = plagiarism_percentage(plag, orig)\n",
        "oraciones_plagio = plagiarised_sentences(plag, orig)\n",
        "print(f\"  - Puede ser plagio: {puede_ser_plagio}.\")\n",
        "print(f\"  - Porcentaje de plagio: {porcentaje_de_plagio}.\")\n",
        "print(f\"  - Oraciones que realizan plagio: {oraciones_plagio}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  - Puede ser plagio: True.\n",
            "  - Porcentaje de plagio: 0.5.\n",
            "  - Oraciones que realizan plagio: ['Me gusta la naranja.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ZsWnd3qZnN",
        "colab_type": "text"
      },
      "source": [
        "## Próximos pasos\n",
        "\n",
        "* Realizar pruebas exhaustivas del método y determinar los thresholds óptimos para el coeficiente de similaridad de Jaccard y la similaridad coseno.\n",
        "* Implementar un sistema de Semantic Role Labeling en español y aplicar el método original propuesto por Paul y Jamal. Evaluar cómo se compara su rendimiento al método reducido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfxTabYRsw26",
        "colab_type": "text"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "1. Merin Paul, Sangeetha Jamal. 2014. An Improved SRL based Plagiarism Detection Technique using Sentence Ranking.\n"
      ]
    }
  ]
}